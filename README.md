# Бинарный сентимент анализ отзывов Yelp Review

## Постановка задачи

Разработка системы для автоматического определения тональности (сентимента) отзывов пользователей на платформе Yelp. Задача заключается в классификации каждого отзыва на один из двух классов: положительный (positive) или отрицательный (negative).

## Формат входных и выходных данных

### Входные данные
Единицей входных данных является одна текстовая строка — текст отзыва пользователя на английском языке.

**Максимальная длина:** `max_length = 384` токенов.

**Обоснование выбора:**
Согласно анализу датасета из HuggingFace, количество символов для 95-го перцентиля находится в районе 1000 символов. Для используемого токенизатора данное значение (`max_length = 384`) является адекватным и достаточным.

### Выходные данные
Выход системы — целое число, представляющее предсказанный класс:
- **1** — положительный сентимент.
- **0** — отрицательный сентимент.

#### Детали процесса инференса
1.  **Вход модели:** `torch.tensor` размера `(batch_size, max_length)`.
2.  **Выход модели (логиты):** `torch.tensor` размера `(batch_size, 2)`.
3.  **Постобработка:**
    - К выходу модели применяется функция `softmax` для получения вероятностного распределения по классам.
    - Выбирается класс с наибольшей вероятностью (argmax).


## Метрики

### Accuracy (Точность)
*   **Описание:** Общая доля правильных ответов.
*   **Назначение:** Интуитивно понятная общая метрика для быстрой оценки.

### F1-Score (F-мера)
*   **Описание:** Гармоническое среднее между точностью (Precision) и полнотой (Recall).
*   **Назначение:** **Основная метрика**, так как она хорошо отражает качество модели на обоих классах, особенно на несбалансированных данных.

### ROC-AUC
*   **Описание:** Площадь под ROC-кривой (Receiver Operating Characteristic).
*   **Назначение:** Показывает, насколько хорошо модель разделяет классы. Используется для сравнения моделей.

### Precision (Точность)
*   **Описание:** Доля правильно предсказанных позитивных срабатываний (негативных отзывов) среди всех срабатываний модели.
*   **Бизнес-контекст:** Позволяет понять, насколько модель соответствует бизнес-целям. С точки зрения бизнеса, мы более сфокусированы на Recall, так как не хотим пропускать негативные отзывы.

### Recall (Полнота)
*   **Описание:** Доля реальных позитивных случаев (негативных отзывов), которые модель смогла обнаружить.
*   **Бизнес-контекст:** **Для нас критически важна качественная полнота (Recall)**, потому что необходимо минимизировать пропуск негативных отзывов.

---

## Предполагаемые значения метрик

### Бейзлайн модель (TF-IDF + Logistic Regression)
*   **Accuracy:** ~0.92 - 0.94
*   **F1-Score:** ~0.92 - 0.94
*   **Recall:** ~0.94
*   **Precision:** ~0.92

### Основная модель (LSTM)
*   **Цель:** Не только немного поднять общий F1-score, но и обеспечить лучший баланс между Precision и Recall, особенно для негативного класса, за счет лучшего понимания контекста и нюансов языка.
*   **Accuracy:** Ожидается улучшение относительно бейзлайна.
*   **F1-Score:** Целевой диапазон **0.93 - 0.95**.
*   **Recall:** Целевой диапазон **0.95 - 0.96**.
*   **Precision:** Целевой диапазон **0.93 - 0.94**.

> **Примечание:** Предполагаемые значения основаны на анализе аналогичных проектов и ноутбуков Kaggle для данного типа задачи (анализ тональности отзывов).


## Валидация

### Разделение данных
*   **Тренировочный и тестовый наборы:** Используется стандартное разделение, предоставленное в датасете (`train` и `test`).
*   **Валидационная выборка:** Для валидации в ходе обучения модели будет выделено **10% от тренировочного набора**.

### Воспроизводимость
Для обеспечения полной воспроизводимости результатов **критически важно** зафиксировать начальное состояние генераторов случайных чисел.

Установите `random seed=42` для всех используемых библиотек:
*   **NumPy:** `np.random.seed(42)`
*   **PyTorch:**
    ```python
    torch.manual_seed(42)
    torch.cuda.manual_seed_all(42)  # если используется GPU
    ```
*   **Python (модуль random):** `random.seed(42)`
*   **Scikit-learn:** Установите параметр `random_state=42` в соответствующих функциях и моделях.

Это обеспечит идентичные результаты при повторных запусках, влияя на:
1.  Разбивку данных на валидационную выборку.
2.  Инициализацию весов нейронной сети.
3.  Процесс обучения (если используются стохастические алгоритмы).


## Датасеты

### Датасеты

### Источник и конфигурация
*   **Источник:** [Hugging Face Datasets](https://huggingface.co/datasets)
*   **Конкретный датасет:** `yelp_polarity`
*   **Описание:** Датасет содержит отзывы пользователей Yelp. Задача — бинарная классификация тональности.
*   **Метки (labels):** `0` (негативный отзыв) или `1` (позитивный отзыв).
*   **Баланс классов:** Классы сбалансированы.

### Объем и размеры выборок
*   **Общий объем:** ~274 МБ.
*   **Язык данных:** Английский.
*   **Длина текстов:** Средняя.
*   **Размеры после преобразования:**
    *   **Тренировочная выборка (train):** ~560,000 примеров.
    *   **Тестовая выборка (test):** ~38,000 примеров.

### Особенности и потенциальные проблемы
1.  **Сленг и опечатки:** Отзывы содержат неформальную лексику, сокращения и орфографические ошибки, характерные для пользовательского контента.
2.  **Ирония и сарказм:** Присутствие иронии и сарказма может быть сложным для корректной интерпретации даже для продвинутых моделей.
3.  **Длинные отзывы:** Некоторые отзывы могут быть очень подробными. Это потребует применения стратегий **обрезки (truncation)** или **упаковки (padding)** для моделей с фиксированной максимальной длиной последовательности (например, BERT, LSTM с фиксированным input size).
легко решается.

## Моделирование
## Архитектура моделей

### Бейзлайн модель
*   **Название:** TF-IDF + Logistic Regression
*   **Описание:** Классический и эффективный пайплайн для классификации текстов.
*   **Векторизация текста:**
    *   Используется `TfidfVectorizer` из `sklearn.feature_extraction.text`.
    *   **Предобработка:** Приведение к нижнему регистру, удаление стоп-слов.
    *   **N-граммы:** Используется диапазон (1,2) для учета как отдельных слов, так и словосочетаний.
*   **Классификатор:**
    *   Линейная логистическая регрессия (`LogisticRegression` из `sklearn.linear_model`).
*   **Обоснование выбора:**
    *   Создает сильный и интерпретируемый базовый уровень.
    *   Очень быстрый в обучении (секунды/минуты).
    *   Не требует GPU для обучения.
    *   Позволяет эффективно сравнить с более сложными нейросетевыми подходами.

### Основная модель
*   **Название:** LSTM (Long Short-Term Memory)
*   **Токенизация:** Предобученный токенизатор из `torchtext` с использованием `'spacy'`.
*   **Архитектура:**

    ```python
    1. Embedding Layer (nn.Embedding)
       - Преобразует индексы токенов в плотные векторные представления.
    
    2. LSTM Layer (nn.LSTM)
       - Обрабатывает последовательность эмбеддингов.
       - Улавливает долгосрочные зависимости и контекст в тексте.
    
    3. Объединяющий слой
       - Используется выход последнего скрытого состояния LSTM или операция глобального пулинга.
    
    4. Dropout Layer (nn.Dropout)
       - Вероятность dropout: 0.2
       - Регуляризация для предотвращения переобучения.
    
    5. Fully Connected Layer (nn.Linear)
       - Проецирует финальное представление на 2 выходных нейрона (для классов 0 и 1).
    ```

*   **Функция потерь:** `nn.CrossEntropyLoss`
*   **Оптимизатор:** `torch.optim.Adam`
*   **Гиперпараметры обучения:**
    *   `batch_size`: 64
    *   `learning_rate`: 0.001
    *   `epochs`: 7
*   **Окружение обучения:** Обучение проводится на CPU (отсутствие доступа к GPU).

## Внедрение

### Развертывание
- Сервис будет развернут в `docker/docker-compose`
- Модель будет развернута на **Triton Inference Server** как сервис в `docker-compose`
- Наш бэкенд будет обращаться к Triton Inference Server для получения предсказаний

### Архитектура сервиса
- Модель обернута в веб-сервис
- Входные данные (текст отзыва) передаются в формате **JSON**
- Сервис возвращает ответ в формате **JSON** с предсказанием

### Дополнительные компоненты

#### 1. Предобработка текста
- Логика токенизации и очистки текста должна быть частью пайплайна

#### 2. Конфигурация
- Все параметры (пути к моделям, параметры токенизатора) вынесены в конфигурационный файл
- Используется **Hydra** для управления конфигурацией

#### 3. Логирование
- Реализовано логирование для отслеживания работы сервиса


# Работа с проектом

## Setup

Клонирование репозитория:

```
git clone https://github.com/shpvckdotov/yelp-review_binary.git
```

После клонирования репозитория перейдите в его папку:

```
cd yelp-review-binary
```

Установите Poetry для управления зависимостями:

```
pip install poetry==2.1.2
```

Установка зависимостей проекта:

```
poetry install
```

Установка хуков для pre-commit:

```
poetry run pre-commit install
```

Запустите проверки:

```
poetry run pre-commit run --all-files
```

## Структура папок

```
├── conf
│   ├── config.yaml
│   ├── infer
│   │   └── infer.yaml
│   ├── logging
│   │   └── logging.yaml
│   ├── model
│   │   └── model.yaml
│   ├── module
│   │   └── module.yaml
│   ├── random
│   │   └── random.yaml
│   └── training
│       └── training.yaml
├── data
│   ├── data.dvc
├── docs
├── download_data.py
├── mlflow.db
├── mlruns
├── models
│   └── epoch=00-val_loss=0.1730.ckpt.dvc
├── 
├── poetry.lock
├── pyproject.toml
├── README.md
├── remote
├── tests
├── triton
│   ├── docker-compose.yaml
│   ├── models_repository
│   │   ├── 1
│   │   └── config.pbtxt
│   └── triton.py
└── yelp-review
    ├── baseline_classifier.py
    ├── convert_to_onnx.py
    ├── data.py
    ├── infer.py
    ├── __init__.py
    ├── lstm_classifier.py
    ├── model.py
    └── train.py
```

## Train

Активируйте окружение:

```
poetry env activate
```
Запустить mlflow в корне проекта.
```
poetry run mlflow server --host 127.0.0.1 --port 8080 --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns

```
Скачайте данные для обучения и тестирования модели из корня проекта:

```
poetry run python download_data.py
```

Запустите модель обучаться:

```
poetry run python yelp-review/train.py
```

## Infer
В конфиге добавьте ckpt_path: models/{чекпоинт модели из директории models}
Запустите infer.py чтобы увидеть скор по метрикам на тестовой выборке в корне.
```
poetry run python yelp-review/infer,py
```
## Production preparation
Обученную модель можно перевести из .ckpt в формат .onnx. Не забудьте поменять
название файла запускаемся из корня (чекпоинт берется из конфига infer):

```
poetry run python yelp-review/convert_to_onnx.py 
```
